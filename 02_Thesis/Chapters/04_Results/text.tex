\section{Results}
\label{chapter:results}

\subsection{Analysis of detected biases per bias and model}
\subsubsection{Bias detections}
\par The histogram in Figure \ref{fig:detections-distribution} portrays a high portion of bias detections around 0. In fact, the amount of detections where there is no difference between the means of the two groups (\textit{bias detected = 0}) is 59.2 \%. This means that in roughly six out of ten cases, the models did not respond differently at all (in their means) to the two prompts. Further, we find that 80.4 \% of all bias detections are within the expectations and interpretation guidelines by \textcite{cohen1988statistical} (between -1 and 1). For our \textit{bias detected (capped)} metric (Equation \ref{eq:bias_detected_capped}), we capture 74.2 \% of the original detections and cap the outliers for interpretability purposes as  we consider all effects above 0.8 as large effect sizes. The distribution displays a slight tendency towards positive values, indicating more biased than unbiased responses (32.2 \% of detections above 0, 8.6 \% of detections below 0).

\begin{figure}[htbp]
    \centering
    \includesvg[width=0.9\textwidth]{/Users/mAx/Documents/Master/04/Master_Thesis/02_Thesis/Chapters/04_Results/Overview/bias_detections_distribution.svg}
    \caption[Distribution plot of bias detections]{\centering \textit{Distribution of bias detections (uncapped). Plot depicts distributions of bias detections between -1.7 and 1.7 which represents 87.4 \% of all detections (for visualization purposes).}}
    \label{fig:detections-distribution}
\end{figure}

\par Aggregating across all biases and models, we find a total of 28 bias detections (\textit{bias detected (capped)} \geq\, 0.5). We display the aggregations as a heatmap in Figure \ref{fig:detections-heatmap}. Our aggregation method described in Chapter \ref{methodologies:analysisbiasmodels} leads to a high density of bias detections around 0 and 1. However, as the scaling in between the minimum and maximum stays untouched, we are still able to apply the interpretation guidelines for small, medium and large effects by \textcite{cohen1988statistical}.

\par The heatmap depicts a high number of bias detections for the \textit{anchoring bias}, the \textit{endowment effect}, the \textit{framing effect} and \textit{loss aversion}. Especially the \textit{anchoring bias} is detected with a large effect in all models. This means that all models are heavily influenced in their estimations when being exposed to a reference point (anchor). Additionally, most models reveal to be biased with regard to the \textit{framing effect}, to varying magnitudes. Generally, the model twins with more parameters seem to be more biased towards this, with the small \textit{Phi3.5} model being an exception. When detected, the \textit{endowment effect} also has a large impact on the models' responses. All models except for \textit{Llama3.1} and \textit{Phi3:medium} are biased towards valuing their own possession higher than an offered item. \textit{Loss aversion}, if detected, shows strong to very strong effects in the models or none at all. Especially the model families by Anthropic and OpenAI show strong tendencies to avoiding losses and therefore taking more risks. Smaller models show less bias towards \textit{loss aversion} except for \textit{Llama3.1:70b} which is less biased than its 8 billion parameter twin.

\begin{figure}[htbp]
    \centering
    \includesvg{/Users/mAx/Documents/Master/04/Master_Thesis/02_Thesis/Chapters/04_Results/Overview/heatmap_detections.svg}
    \caption[Heatmap of bias detections grouped by biases and models]{\centering \textit{Detected biases grouped by biases and models. 0 signals non-existent and 1 fully-existent bias. Detailed calculation and aggregation of the target variable described in chapters \ref{methodologies:biasdetector} and \ref{methodologies:analysisbiasmodels}, respectively.}}
    \label{fig:detections-heatmap}
\end{figure}

\par Some biases were not detected in any of the models. Both the \textit{gambler's fallacy} and \textit{category size bias} are biases that examine the statistical understanding of independent subjects and events. The LLMs seem to not show any bias towards these fallacies. The \textit{sunk cost fallacy} is also not detected in any of the models. Humans generally prefer the option with the larger sunk costs, independent of their actual emotional preference. Interestingly, we find that the models not only do not exhibit this bias, but prefer the emotionally preferred option with lower sunk costs. This could be caused by the missing relationship and reference towards the monetary value of the sunk costs.

\par The \textit{transaction utility bias} is an extreme case amongst our biases as it is not detected in any models except for \textit{GPT-4o} and \textit{Claude-3.5-Sonnet}. The experiment aimed to investigate if participants would shift your purchasing decision based on the transaction utility of the product (difference between prices but linked to a 20-minute drive). While human participants altered their decision based on the relative amount of money saved to the purchasing prices, most of the models understood that both scenarios had the same absolute price difference. It seems that amongst all models, only \textit{GPT-4o} and \textit{Claude-3.5-Sonnet} were able to understand the transaction utility and time implications of the experiment.

\par From a model perspective, \textit{GPT-4o} and \textit{Claude-3.5-Sonnet} are the most biased models amongst our bias and model combinations. While the \textit{anchoring bias} is not as strongly detected as in other models, \textit{GPT-4o} either shows strong bias detections or no bias detections at all. The smaller twin \textit{GPT-4o-Mini} shows similar but less pronounced behavior except for the anchoring bias. We find similar patterns for the \textit{Claude}, \textit{Gemma} and \textit{Llama} models, where the smaller model often shows less biased behavior than the larger model. The \textit{Phi} models show a different pattern, where the larger model is less biased than the smaller model. \textit{Phi3:Medium} is in fact the least biased model of our selections. This could be due to the later training of \textit{Phi3.5} and thus newer data with model improvements or the much larger context length.


\subsubsection{Homogeneities of bias detections}
\par We also test the detected biases for homogeneity. The focus lies on whether a bias was detected and not on the exact magnitude. Therefore, in contrast to the aggregated bias detections, we transform the original bias detections before calculating the homogeneities, then set limits at 0 and 1 and display them in a heatmap (see Figure \ref{fig:homogeneity-heatmap}). We particularly find homogeneity for non-bias detections.

\begin{figure}[t!]
    \centering
    \includesvg{/Users/mAx/Documents/Master/04/Master_Thesis/02_Thesis/Chapters/04_Results/Homogeneity/homogeneity_heatmap.svg}
    \caption[Heatmap of homogeneities grouped by biases and models]{\centering \textit{Homogeneities of capped effect sizes (between 0 and 1) grouped by biases and models. 0 signals complete heterogeneity and 1 complete homogeneity. Detailed calculation of homogeneity detailed in chapter \ref{methodologies:analysisbiasmodels}.}}
    \label{fig:homogeneity-heatmap}
\end{figure}

\par As we expected, slight and strong bias detections are quite heterogeneous across the bias-model combinations. This indicates that the effect sizes (even though capped) are not consistent across the combinations. The averaging of the effect sizes of all scenarios and model temperatures could be one reason for the heterogeneity. The small but perhaps influential adaptions to the model prompts and their response behavior could lead to slightly different model responses and thus effect sizes. Further, re-initializing the models between each experiment could also lead to inconsistent responses. Some exceptions with either very homogeneous, high bias detections or very heterogeneous, low bias detections are present and are highlighted in Table \ref{tab:homogeneity_anomalies}. A low homogeneity even though we did not detect a bias could indicate that in some scenarios or with some model temperatures, a bias is more present than in others.

\subsubsection{Regression analysis of biases and models}
\par The regressions on the uncapped and capped bias detections (Table \ref{tab:summary_regr_allexper}) show that the bias detections of the models significantly depend on the explored bias ($p < 0.05$). This is consistent with the hypothesis that the detections seem to especially be dependent of the specific bias itself, as suggested by the heatmap in Figure \ref{fig:detections-heatmap}.

\begin{table}[h!]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{lccc|ccc}
        \hline
        \textbf{Target variable} & \multicolumn{3}{c}{\textbf{bias\_detected (R\textsuperscript{2}=7.2\%)}}
        & \multicolumn{3}{c}{\textbf{bias\_detected\_capped (R\textsuperscript{2}=36.7\%)}} \\
        \textit{Variable} & \textit{Coef.} & \textit{Std. Err.} & \textit{p-value} & \textit{Coef.} & \textit{Std. Err.} & \textit{p-value} \\
        \hline
        Intercept & 3.9224 & 1.197 & 0.001 & 0.6241 & 0.038 & 0.000 \\
        Bias: category size bias & -7.3005 & 0.991 & 0.000 & -0.6212 & 0.032 & 0.000 \\
        Bias: endowment effect & -2.0941 & 0.990 & 0.034 & -0.2625 & 0.031 & 0.000 \\
        Bias: framing effect & -2.7081 & 0.990 & 0.006 & -0.4660 & 0.031 & 0.000 \\
        Bias: gamblers fallacy & -3.2171 & 0.990 & 0.001 & -0.6693 & 0.031 & 0.000 \\
        Bias: loss aversion & -2.0655 & 0.990 & 0.037 & -0.3604 & 0.031 & 0.000 \\
        Bias: sunk cost fallacy & -3.2323 & 0.990 & 0.001 & -0.6831 & 0.031 & 0.000 \\
        Bias: transaction utility & -2.9421 & 0.990 & 0.003 & -0.5774 & 0.031 & 0.000 \\
        Model: claude-3.5-sonnet & 1.8203 & 1.106 & 0.100 & 0.0938 & 0.035 & 0.008 \\
        Model: gemma2 & 1.2924 & 1.106 & 0.243 & -0.0351 & 0.035 & 0.318 \\
        Model: gemma2:27b & 0.0876 & 1.106 & 0.937 & -0.0649 & 0.035 & 0.065 \\
        Model: gpt-4o & 0.9837 & 1.106 & 0.374 & 0.1783 & 0.035 & 0.000 \\
        Model: gpt-4o-mini & 1.1737 & 1.106 & 0.289 & 0.0551 & 0.035 & 0.117 \\
        Model: llama3.1 & -1.0772 & 1.106 & 0.330 & -0.0240 & 0.035 & 0.496 \\
        Model: llama3.1:70b & 0.1346 & 1.108 & 0.903 & 0.0046 & 0.035 & 0.896 \\
        Model: phi3.5 & -4.3647 & 1.106 & 0.000 & -0.0255 & 0.035 & 0.468 \\
        Model: phi3:medium & -0.1172 & 1.106 & 0.916 & -0.0418 & 0.035 & 0.235 \\
        Scenario: 1\_no\_persona & -2.1589 & 0.700 & 0.002 & 0.0081 & 0.022 & 0.716 \\
        Scenario: 2\_odd\_numbers & 0.5583 & 0.700 & 0.425 & -0.0006 & 0.022 & 0.977 \\
        Scenario: 3\_large\_numbers & -0.5939 & 0.700 & 0.396 & -0.0734 & 0.022 & 0.001 \\
        Temperature & -0.1271 & 0.458 & 0.781 & 0.0692 & 0.015 & 0.000 \\
        \hline
    \end{tabular}
    }
    \caption[Summary of regressions of experiment variables on bias detections]{\centering  \textit{Summarized overview of regressions of experiment variables on bias detections. More detailed results can be found in Appendix \ref{appendix:regr_allexper}.}}
    \label{tab:summary_regr_allexper}
\end{table}


\par The regression on \textit{bias detected} has a very low explained variance while the regression on \textit{bias detected (capped)} has a higher explained variance. This likely reflects the influence of outliers and variance in the exact magnitude of the bias detections, aligning with the heterogeneity analysis of the bias detections. For the latter regression, most models do not significantly influence bias detections except for the two largest models, \textit{GPT-4o} and \textit{Claude-3.5-Sonnet}. Both have significant positive effects on the bias detections, indicating that these models are more prone to the biases.


\subsection{Impact of scenarios}
\label{results:scenarioimpact}
\par From our regression results in Table \ref{tab:summary_regr_allexper}, we find that the exclusion of the persona prompt leads to significantly lower bias detections across the unmodified effects. This supports our expectation that the persona leads to more human-like and thus more biased responses. Though on the capped bias detections, the persona prompt does not have a significant influence, suggesting that it primarily amplifies the extremity of the bias detections. However, this could also be due to the capping process, which may limit the ability to fully capture the effect of changes in bias detection.

\begin{figure}[htbp]
    \centering
    \includesvg[width=0.7\textwidth]{/Users/mAx/Documents/Master/04/Master_Thesis/02_Thesis/Chapters/04_Results/Scenarios/scenario_detections.svg}
    \caption[Distribution plots of bias detections by scenarios]{\centering \textit{Bias detections (uncapped) grouped by scenarios. Plot depicts distributions of bias detections between -5 and 5 (for visualization purposes).}}
    \label{fig:scenario-detections}
\end{figure}

\par A glimpse at the distributions per scenario in Figure \ref{fig:scenario-detections} and the regression results of the scenarios on \textit{bias detected (capped)} extend our analysis. The distribution plots do not display clear differences except a slight decrease of minimal bias detections in the scenario with extremely large values. This aligns with the regression results where this scenario has the only significant effect with a slightly negative effect on the bias detections compared to the base scenario. The scenario with similar but odd numerical values did not show any significant impact in both regressions. This suggests that the models are more likely to exhibit biases when the values are realistic and thus possibly closer to the training data.

\par Further, the regressions exclusively of the scenarios on the bias detections (Appendix \ref{appendix:regr_scenarios}) indicate that the explained variance of the scenarios is very low ($R^2 \leq 1 \%$). The low $R^2$ indicates that scenarios alone do not sufficiently explain the variability in bias detections, suggesting other factors play a more prominent role. While some scenarios do show slight significant impacts and tendencies (missing persona and large numbers lead to lower bias detections in the models), the overall influence of the scenarios on the bias detections appears to be minimal.


\subsection{Model feature analysis}
\label{results:modelanalysis}

\begin{table}[h!]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{lccc|ccc}
        \hline
        \textbf{Target variable} & \multicolumn{3}{c}{\textbf{bias\_detected (R\textsuperscript{2}=2.4\%)}}
        & \multicolumn{3}{c}{\textbf{bias\_detected\_capped (R\textsuperscript{2}=4.1\%)}} \\
        \textit{Variable} & \textit{Coef.} & \textit{Std. Err.} & \textit{p-value} & \textit{Coef.} & \textit{Std. Err.} & \textit{p-value} \\
        \hline
        Intercept                   & -24.490 & 6.469 & 0.000 & -0.0198 & 0.247 & 0.936 \\
        Temperature                 & -0.1295 & 0.468 & 0.782 & 0.0691 & 0.018  & 0.000 \\
        \triangle Release date      & 0.0152 & 0.023 & 0.517 & -0.0006 & 0.001 & 0.497 \\
        \triangle Last-updated date & -0.0020 & 0.028 & 0.943 & 0.0005 & 0.001 & 0.638 \\
        \triangle Training data cutoff date & -0.0046 & 0.006 & 0.413 & 0.0004 & 0.000 & 0.038 \\
        Number of parameters        & -0.0050 & 0.013 & 0.710 & 0.0015 & 0.001  & 0.004 \\
        Context length              & -0.0012 & 0.016 & 0.940 & -0.0004 & 0.001 & 0.555 \\
        MMLU                        & 0.0554 & 0.113 & 0.624 & -0.0065 & 0.004 & 0.129 \\
        Chatbot Arena               & 0.0168 & 0.008 & 0.026 & 0.0004 & 0.000 & 0.130 \\
        \hline
    \end{tabular}
    }
    \caption[Summary of regressions of model features on bias detections]{\centering  \textit{Summarized overview of regressions of model features on bias detections. More detailed results can be found in Appendix \ref{appendix:regr_modelfeats}.}}
    \label{tab:summary_regr_modelfeats}
\end{table}

\par To further investigate the language models and their bias detections, we regress selected model features on both \textit{bias detected} and \textit{bias detected (capped)}. The key results of the regressions are displayed in Table \ref{tab:summary_regr_modelfeats}. As for the scenario regressions in Chapter \ref{results:scenarioimpact}, the regression models have little explained variance, though the latter regression without the extreme effects fits the data slightly better. For this regression, we find some significant effects. Most notably, a higher temperature significantly increases the bias detection in a model. This aligns with our expectations as a higher model temperature generally leads to more creative and random responses, thus probably differing more between the two prompts in each experiment and apparently leading to higher biases. Further, larger models with more parameters show slight gains for detecting biases. This overlaps with our previous analysis where the larger models \textit{GPT-4o} and \textit{Claude-3.5-Sonnet} showed higher bias detections than other models.

\par We also find a significant though minor effect for the knowledge cutoff of the models. An earlier training data cutoff leads to a slightly higher \textit{bias detected (capped)}. This could be due to enhanced data curation and preprocessing as well as new training methods leading to less model intake of biases. However, the effect is minor and should not be overinterpreted. Both model evaluation benchmarks \textit{MMLU} and the \textit{Chatbot Arena Score} do not significantly explain the existence of a bias. Though the \textit{Chatbot Arena Score} has a significant impact on the uncapped \textit{bias detected}, the effect is small. Still, this points out that the human-likeliness scores in the Chatbot Arena could be a minor indicator for models with more human-like behavior and biases. In neither regression, the release and last-updated dates had significant effects on the bias detections. This suggests that amongst our selected models, the model's age and the time since the last update do not significantly influence the bias detections.
