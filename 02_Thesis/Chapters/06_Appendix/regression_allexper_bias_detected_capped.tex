\begin{center}
\begin{tabular}{lclc}
\toprule
\textbf{Dep. Variable:}                   & bias\_detected\_capped & \textbf{  R-squared:         } &     0.367   \\
\textbf{Model:}                           &          OLS           & \textbf{  Adj. R-squared:    } &     0.359   \\
\textbf{Method:}                          &     Least Squares      & \textbf{  F-statistic:       } &     45.78   \\
\textbf{Date:}                            &    Sat, 04 Jan 2025    & \textbf{  Prob (F-statistic):} & 6.81e-141   \\
\textbf{Time:}                            &        22:17:33        & \textbf{  Log-Likelihood:    } &   -409.96   \\
\textbf{No. Observations:}                &           1599         & \textbf{  AIC:               } &     861.9   \\
\textbf{Df Residuals:}                    &           1578         & \textbf{  BIC:               } &     974.8   \\
\textbf{Df Model:}                        &             20         & \textbf{                     } &             \\
\textbf{Covariance Type:}                 &       nonrobust        & \textbf{                     } &             \\
\bottomrule
\end{tabular}
\begin{tabular}{lcccccc}
                                          & \textbf{coef} & \textbf{std err} & \textbf{t} & \textbf{P$> |$t$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
\midrule
\textbf{Intercept}                        &       0.6241  &        0.038     &    16.386  &         0.000        &        0.549    &        0.699     \\
\textbf{C(bias)[T.category size bias]}    &      -0.6212  &        0.032     &   -19.711  &         0.000        &       -0.683    &       -0.559     \\
\textbf{C(bias)[T.endowment effect]}      &      -0.2625  &        0.031     &    -8.338  &         0.000        &       -0.324    &       -0.201     \\
\textbf{C(bias)[T.framing effect]}        &      -0.4660  &        0.031     &   -14.805  &         0.000        &       -0.528    &       -0.404     \\
\textbf{C(bias)[T.gamblers fallacy]}      &      -0.6693  &        0.031     &   -21.263  &         0.000        &       -0.731    &       -0.608     \\
\textbf{C(bias)[T.loss aversion]}         &      -0.3604  &        0.031     &   -11.449  &         0.000        &       -0.422    &       -0.299     \\
\textbf{C(bias)[T.sunk cost fallacy]}     &      -0.6831  &        0.031     &   -21.703  &         0.000        &       -0.745    &       -0.621     \\
\textbf{C(bias)[T.transaction utility]}   &      -0.5774  &        0.031     &   -18.344  &         0.000        &       -0.639    &       -0.516     \\
\textbf{C(model)[T.claude-3.5-sonnet]}    &       0.0938  &        0.035     &     2.664  &         0.008        &        0.025    &        0.163     \\
\textbf{C(model)[T.gemma2]}               &      -0.0351  &        0.035     &    -0.999  &         0.318        &       -0.104    &        0.034     \\
\textbf{C(model)[T.gemma2:27b]}           &      -0.0649  &        0.035     &    -1.845  &         0.065        &       -0.134    &        0.004     \\
\textbf{C(model)[T.gpt-4o]}               &       0.1783  &        0.035     &     5.067  &         0.000        &        0.109    &        0.247     \\
\textbf{C(model)[T.gpt-4o-mini]}          &       0.0551  &        0.035     &     1.567  &         0.117        &       -0.014    &        0.124     \\
\textbf{C(model)[T.llama3.1]}             &      -0.0240  &        0.035     &    -0.682  &         0.496        &       -0.093    &        0.045     \\
\textbf{C(model)[T.llama3.1:70b]}         &       0.0046  &        0.035     &     0.130  &         0.896        &       -0.065    &        0.074     \\
\textbf{C(model)[T.phi3.5]}               &      -0.0255  &        0.035     &    -0.725  &         0.468        &       -0.095    &        0.043     \\
\textbf{C(model)[T.phi3:medium]}          &      -0.0418  &        0.035     &    -1.188  &         0.235        &       -0.111    &        0.027     \\
\textbf{C(scenario)[T.1\_no\_persona]}    &       0.0081  &        0.022     &     0.363  &         0.716        &       -0.036    &        0.052     \\
\textbf{C(scenario)[T.2\_odd\_numbers]}   &      -0.0006  &        0.022     &    -0.028  &         0.977        &       -0.044    &        0.043     \\
\textbf{C(scenario)[T.3\_large\_numbers]} &      -0.0734  &        0.022     &    -3.300  &         0.001        &       -0.117    &       -0.030     \\
\textbf{temperature}                      &       0.0692  &        0.015     &     4.750  &         0.000        &        0.041    &        0.098     \\
\bottomrule
\end{tabular}
\begin{tabular}{lclc}
\textbf{Omnibus:}       & 99.364 & \textbf{  Durbin-Watson:     } &    2.064  \\
\textbf{Prob(Omnibus):} &  0.000 & \textbf{  Jarque-Bera (JB):  } &  117.878  \\
\textbf{Skew:}          &  0.624 & \textbf{  Prob(JB):          } & 2.53e-26  \\
\textbf{Kurtosis:}      &  3.459 & \textbf{  Cond. No.          } &     16.8  \\
\bottomrule
\end{tabular}
%\caption{OLS Regression Results}
\end{center}

Notes: \newline
 [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.