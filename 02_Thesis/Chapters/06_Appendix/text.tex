\appendix

\section{Bias details and experiments}
\label{appendix:biases}

\begin{table}[h!]
    \centering
    \caption[Bias overview and experiment questions]{\centering \textit{Overview of the bias concepts and the corresponding experiment questions. "A" refers to the (perhaps modified) question for the control group, "B" for the test group. "Expect" refers to the expected results.}}
    \label{tab:bias_overview}
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{l|p{7.8cm}p{7.8cm}}
    \toprule
    \textbf{Bias} & Anchoring bias & Category size bias \\
    \midrule
    \textbf{Concept} & Reliance on previous anchor for subsequent decision & Misjudgment of probabilities due to category size \\
    \textbf{Source} & \textcite{tversky1974judgment} & \textcite{isaac2014judging} \\
    \textbf{A} & Do you think the portion of African countries in the United Nations is higher or lower than \textbf{10\%}? Now that you have thought about that, what would you estimate the actual exact portion to be? Answer the percentage between 0 and 100 (Please only answer the percentage as a number without the \% sign.). \% \_\_ & Imagine a lottery containing \textbf{15} balls. Balls \textbf{1} to \textbf{5} are black, \textbf{6} to \textbf{10} are gray, and \textbf{11} to \textbf{15} are white. If one ball is drawn from the urn, what is the probability that it will be ball \textbf{8}? Answer the percentage between 0 and 100. \% \_\_ \\
    \textbf{B} & Do you think the portion of African countries in the United Nations is higher or lower than \textbf{65\%}? Now that you have thought about that, what would you estimate the actual exact portion to be? Answer the percentage between 0 and 100 (Please only answer the percentage as a number without the \% sign.). \% \_\_ & Imagine a lottery containing \textbf{15} balls. Balls \textbf{1} to \textbf{2} are black, \textbf{3} to \textbf{13} are gray, and \textbf{14} to \textbf{15} are white. If one ball is drawn from the urn, what is the probability that it will be ball \textbf{8}? Answer the percentage between 0 and 100. \% \_\_ \\
    \textbf{Expect} & Higher estimations in B due to higher anchor & Higher estimations in B due to larger category size \\
    \midrule
    \bottomrule
    \end{tabular}}
\end{table}

\begin{table}[h!]
    \ContinuedFloat % Marks this table as part of the previous one
    \centering
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{l|p{7.8cm}p{7.8cm}}
    \toprule
    \textbf{Bias} & Endowment effect & Framing effect \\
    \midrule
    \textbf{Concept} & Overvaluation of owned items and vice versa & Different valuations and decision-making due to framing \\
    \textbf{Source} & \textcite{kahneman1990experimental} & \textcite{tversky1981framing} \\
    \textbf{A} & I show you a mug from a distance. You can see it but you cannot touch it. The mug was originally priced at \textbf{\$4}, but the value of the mug is different for different individuals. What price would you buy it for? \$ \_\_ & Imagine that you have decided to see a play and paid the admission price of \textbf{\$10} per ticket. As you enter the theater, you discover that you have lost the ticket. The seat was not marked and the ticket cannot be recovered. Would you pay \textbf{\$10} for another ticket to the play? Choose between A) Yes or B) No. \_\_ \\
    \textbf{B} & I hand you a mug. You now own the mug. You can feel it and look at it in detail from all angles. The mug was originally priced at \textbf{\$4}, but the value of the mug is different for different individuals. What price would you sell it for? \$ \_\_ & Imagine that you have decided to see a play where admission is \textbf{\$10}. As you enter the theater, you discover that you have lost a \textbf{\$10} bill. Would you still pay \textbf{\$10} for a ticket to the play? Choose between A) Yes or B) No. \_\_ \\
    \textbf{Expect} & Higher valuation in B due to ownership & Different decision-making in A and B due to framing \\
    \midrule
    \bottomrule
    \end{tabular}}
\end{table}

\newpage
\begin{table}[h!]
    \ContinuedFloat % Marks this table as part of the previous one
    \centering
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{l|p{7.8cm}p{7.8cm}}
    \toprule
    \textbf{Bias} & Gambler's fallacy & Loss aversion \\
    \midrule
    \textbf{Concept} & Misunderstanding of independent events & Avoidance of losses through risk-taking over gains \\
    \textbf{Source} & \textcite{leonard2015gambling} & \textcite{thaler2015misbehaving} \\
    \textbf{A} & A fair coin has been flipped \textbf{6} times and has come up heads half the time and tails half the time. What is the probability that the next flip will be heads? Answer the percentage between 0 and 100. \% \_\_ & Assume yourself richer by \textbf{\$300} than you are today. You are offered a choice between A. A sure gain of \textbf{\$100}, or B. A 50\% chance to gain \textbf{\$200} and a 50\% chance to lose \$0. Choose between A and B. \_\_ \\
    \textbf{B} & A fair coin has been flipped \textbf{6} times and has come up heads each time. What is the probability that the next flip will be heads? Answer the percentage between 0 and 100. \% \_\_ & Assume yourself richer by \textbf{\$500} than you are today. You are offered a choice between A. A sure loss of \textbf{\$100}, or B. A 50\% chance to lose \textbf{\$200} and a 50\% chance to lose \$0. Choose between A and B. \_\_ \\
    \textbf{Expect} & Higher estimations in B due to gambler's fallacy & Higher portion of risk-seeking option in A due to loss aversion \\
    \midrule
    \bottomrule
    \end{tabular}}
\end{table}

\begin{table}[h!]
    \ContinuedFloat % Marks this table as part of the previous one
    \centering
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{l|p{7.8cm}p{7.8cm}}
    \toprule
    \textbf{Bias} & Sunk cost fallacy & Transaction utility theory \\
    \midrule
    \textbf{Concept} & Overvaluation of past investments & Decision-making based on relative price differences \\
    \textbf{Source} & \textcite{arkes1985psychology} & \textcite{thaler1983transaction} \\
    \textbf{A} & Assume that you have spent \textbf{\$50} on a ticket for a weekend ski trip to Michigan. Several weeks later you buy a \textbf{\$50} ticket for a weekend ski trip to Wisconsin. You think you will enjoy the Wisconsin ski trip more than the Michigan ski trip. As you are putting your just-purchased Wisconsin ski trip ticket in your wallet, you notice that the Michigan ski trip and the Wisconsin ski trip are for the same weekend! Itâ€™s too late to sell either ticket, and you cannot return either one. You must use one ticket and not the other. Which ski trip will you go on? A) \textbf{\$50} ski trip to Michigan B) \textbf{\$50} ski trip to Wisconsin. \_\_ & You set off to buy a new television. At the store where you expect to buy it, you find that the price is \textbf{\$650}. A clerk informs you that the same item is available at another branch of the same store for on \textbf{\$640}. The store is a 20-minute drive away and the clerk assures you that they have what you want there. Do you buy A) at the initial store or B) go to the other store? Choose between A and B. \_\_ \\
    \textbf{B} & Assume that you have spent \textbf{\$100} on a ticket for a weekend ski trip to Michigan. Several weeks later you buy a \textbf{\$50} ticket for a weekend ski trip to Wisconsin. ...\textit{identical to A}... Which ski trip will you go on? A) \textbf{\$100} ski trip to Michigan B) \textbf{\$50} ski trip to Wisconsin. \_\_ & You set off to buy a new radio. At the store where you expect to buy it, you find that the price is \textbf{\$35}. A clerk informs you that the same item is available at another branch of the same store for on \textbf{\$25}. The store is a 20-minute drive away and the clerk assures you that they have what you want there. Do you buy A) at the initial store or B) go to the other store? Choose between A and B. \_\_ \\
    \textbf{Expect} & Higher portion of choosing the expensive and emotionally less-preferred option in B & Majority choosing the cheaper option in A \\
    \bottomrule
    \end{tabular}}
\end{table}

\par All \textbf{bold} variables are the adapted variables in the scenarios.



\newpage
\section{Model details and features}
\label{appendix:models}

\begin{table}[h!]
    \centering
    \caption[Model comparison table]{\centering \textit{Comparison of selected models and their features}}
    \label{tab:model_comparison}
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{llll}
    \toprule
    Model & Release Date & Last Updated Date & Training Data Cutoff Date \\
    \midrule
    claude-3-haiku & Mar 7, 2024 & Mar 7, 2024 & Aug, 2023 \\
    claude-3.5-sonnet & Jun 20, 2024 & Jun 20, 2024 & Apr, 2024 \\
    gemma2 & Jun 27, 2024 & Aug 4, 2024 & Jun, 2024 \\
    gemma2:27b & Jun 27, 2024 & Aug 4, 2024 & Jun, 2024 \\
    gpt-4o-mini & Jul 18, 2024 & Jul 18, 2024 & Oct, 2023 \\
    gpt-4o & May 13, 2024 & Aug 6, 2024 & Oct, 2023 \\
    llama3.1 & Jul 23rd, 2024 & Aug 11, 2024 & Dec, 2023 \\
    llama3.1:70b & Jul 23rd, 2024 & Aug 11, 2024 & Dec, 2023 \\
    phi3.5 & Aug 20, 2024 & Aug 20, 2024 & Oct, 2023 \\
    phi3:medium & Apr 23rd, 2024 & Aug 4, 2024 & Oct, 2023 \\
    \midrule
    \bottomrule
    \end{tabular}}
\end{table}

\begin{table}[h!]
    \ContinuedFloat % Marks this table as part of the previous one
    \centering
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{lllll}
    \toprule
    Model & \# Parameters (bn) & Context Length & MMLU & Chatbot Arena** \\
    \midrule
    claude-3-haiku & 20* & 200,000 & 75.2 & 1,179 \\
    claude-3.5-sonnet & 175* & 200,000 & 88.7 & 1,268 \\
    gemma2 & 9 & 8,192 & 71.3 & 1,191 \\
    gemma2:27b & 27 & 8,192 & 75.2 & 1,220 \\
    gpt-4o-mini & 40* & 128,000 & 82 & 1,273 \\
    gpt-4o & 175* & 128,000 & 88.7 & 1,265 \\
    llama3.1 & 8 & 128,000 & 73 & 1,176 \\
    llama3.1:70b & 70 & 128,000 & 86 & 1,248 \\
    phi3.5 & 4 & 128,000 & 69* & 1,037 \\
    phi3:medium & 14 & 4,000 & 78 & 1,123 \\
    \bottomrule
    \end{tabular}}
    \caption*{*Approximated values due to lack of official documentation  **\textcite{huggingface2024chatbotarena}}
\end{table}

% \begin{sidewaystable}[htbp]
%     \centering
%     \adjustbox{max width=\textheight}{
%     \begin{tabular}{llllllll}
%         \toprule
%         Model & Release Date & Last Updated Date & Training Data Cutoff Date & Number Parameters & Context Length & MMLU & Chatbot Arena \\
%         \midrule
%         claude-3-haiku & 294 & 294 & 513 & 20 & 200 & 75.2 & 1179 \\
%         claude-3.5-sonnet & 189 & 189 & 269 & 70 & 200 & 88.7 & 1268 \\
%         gemma2 & 182 & 144 & 208 & 9 & 8192 & 71.3 & 1191 \\
%         gemma2:27b & 182 & 144 & 208 & 27 & 8192 & 75.2 & 1220 \\
%         gpt-4o-mini & 161 & 161 & 452 & 175 & 128 & 82 & 1273 \\
%         gpt-4o & 227 & 142 & 452 & 40 & 128 & 88.7 & 1265 \\
%         llama3.1 & 156 & 137 & 391 & 8 & 128 & 73 & 1176 \\
%         llama3.1:70b & 156 & 137 & 391 & 70 & 128 & 86 & 1248 \\
%         phi3.5 & 128 & 128 & 452 & 4 & 128 & 69 & 1037 \\
%         phi3:medium & 247 & 144 & 452 & 14 & 4 & 78 & 1123 \\
%         \bottomrule
%     \end{tabular}}
%     \caption[Model comparison table]{\centering \textit{Comparison of selected models and their features}}
%     % \label{tab:model_comparison}
% \end{sidewaystable}

\par For most of the models, we were able to collect relevant information. However, there is less official documentation on the closed-source models. Following are the sources:
\begin{itemize}
    \item \textbf{Claude-3 \& 3.5}: \textcite{anthropic2024claude, anthropic2024claude2, decoder2024claudeassistant, felloai2024claudeai, neoteric2024claude3_5}
    \item \textbf{Gemma2}: \textcite{team2024gemma}
    \item \textbf{GPT-4o}: \textcite{explodingtopics2024gptparameters, furia2024gpt4o, openai2024gpt4o, openai2024gpt4omini, yub2024gpt4o}
    \item \textbf{Llama3.1}: \textcite{dubey2024llama, huggingface2024llama3_1_8b, meta2024llama31}
    \item \textbf{Phi3 \& 3.5}: \textcite{abdin2024phi, huggingface2024phi3_medium, huggingface2024phi3_5_mini}
\end{itemize}

\newpage
\section{Exemplary code snippet of experiment run}
\label{appendix:example_code}

\par Example code for \textit{Llama 3.1:70b} and \textit{framing effect} (question A, base scenario):

% Define GitHub-inspired color scheme
\definecolor{bg}{HTML}{F6F8FA} % Light gray background
\definecolor{comment}{HTML}{6A737D} % Gray for comments
\definecolor{keyword}{HTML}{D73A49} % Red for keywords
\definecolor{string}{HTML}{032F62} % Blue for strings
\definecolor{function}{HTML}{005CC5} % Dark blue for functions
\definecolor{variable}{HTML}{E36209} % Orange for variables

% Customize listings
\lstdefinestyle{GitHubStyle}{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{keyword}\bfseries,
    commentstyle=\color{comment}\itshape,
    stringstyle=\color{string},
    identifierstyle=\color{function},
    backgroundcolor=\color{bg},
    numberstyle=\tiny\color{comment},
    numbers=left,
    stepnumber=1,
    numbersep=10pt,
    frame=single,
    framesep=5pt,
    rulecolor=\color{black},
    tabsize=4,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    columns=flexible, % Makes wrapping better
    linewidth=\textwidth, % Ensure it fits within text width
    breakindent=0pt, % Prevent indentation for wrapped lines
    keepspaces=true
}
\lstset{style=GitHubStyle}

\lstinputlisting[language=Python, style=GitHubStyle]{Chapters/06_Appendix/example_code.py}

\newpage
\section{Sampling variance and mean aggregation}
\label{appendix:samplingvar_mean}

\par Formula for the (approximated) sampling variance $\sigma^2_{e_{i}}$ of Cohen's d \parencite{borenstein2021introduction, goulet2018review, morris2002combining}:
\begin{equation} \label{eq:variance_sampling}
    \sigma^2_{e_{i}} = \frac{\nu}{\nu - 2} \times \frac{2}{\tilde{n}} \left( 1 + \frac{\tilde{n}}{2} \delta^2 \right) - \frac{\delta^2}{J(\nu)^2}
\end{equation}
\hspace{0.5cm} \textit{where:} \\
\hspace*{3em}
\begin{tabular}{rl}
    $\delta$:& unweighted population effect size = $\frac{\sum_{i=1}^{n} d_{i}}{n}$ \\
    $J(\nu)$:& Hedges correction factor = $\frac{\Gamma\left(\frac{1}{2} \nu\right)}{\sqrt{\frac{\nu}{2}} \, \Gamma\left(\frac{1}{2} (\nu - 1)\right)} \approx 1 - \frac{3}{4 \nu - 1}$ \parencite{hedges1981distribution} \\
    $\tilde{n}$:& harmonic mean of the sample sizes = $\frac{n_{pre} \times n_{post}}{n_{pre} + n_{post}}$ \\
    $N$:& total number of observations = $n_{pre} + n_{post}$ \\
    $\nu$:& degrees of freedom = $n_{pre} + n_{post} - 2$ \\
\end{tabular} \\

\par Formula for the variance due to the sampling error $\hat{\sigma}^2_{e}$ \parencite{morris2002combining}:
\begin{equation} \label{eq:variance_sampling_total}
    \hat{\sigma}^2_{e} = \frac{n}{\sum_{i=1}^{n} \frac{1}{\hat{\sigma}^2_{e_{i}}}}
\end{equation}
\hspace{0.5cm} \textit{where} $\hat{\sigma}^2_{e_{i}}$: approximated sampling variance of Cohen's d

\par Formula for the weighted mean aggregation of Cohen's d \parencite{borenstein2021introduction, hedges1985statistical, morris2002combining}:
\begin{equation} \label{eq:mean_weighted}
    \bar{d} = \frac{\sum_{i=1}^{n} w_{i} d_{i}}{\sum_{i=1}^{n} w_{i}}
\end{equation}
\hspace{0.5cm} \textit{where:} \\
\hspace*{3em}
\begin{tabular}{rl}
    $w_{i}$:& weights as reciprocals of approximated sampling variance = $\frac{1}{\hat{\sigma}^2_{e_{i}}}$ \\
    $d_{i}$:& Cohen's d effect size \\
\end{tabular} \\

\par Similarly, the formula for the observed variance $\hat{\sigma}^2_{d}$ across effect sizes \parencite{morris2002combining}:
\begin{equation} \label{eq:variance_observed}
    \hat{\sigma}^2_{d} = \frac{\sum_{i=1}^{n} w_{i} (d_{i}-\bar{d})}{\sum_{i=1}^{n} w_{i}}
\end{equation}
\hspace{0.5cm} \textit{where:} \\
\hspace*{3em}
\begin{tabular}{rl}
    $w_{i}$:& weights as reciprocals of approximated sampling variance = $\frac{1}{\hat{\sigma}^2_{e_{i}}}$ \\
    $d_{i}$:& Cohen's d effect size \\
    $\bar{d}$:& mean of Cohen's d effect sizes \\
\end{tabular} \\

\newpage
\par If $n_{pre} = n_{post}$ are constant across all effect sizes, the sampling variance $\sigma^2_{e_{i}}$ and the weights $w_{i}$ are also constant. Thus, the mean aggregation $\bar{d}$ is the same as the unweighted mean. The same applies for the observed variance $\hat{\sigma}^2_{d}$:
\begin{equation} \label{eq:mean_unweighted}
    \bar{d} = \frac{\sum_{i=1}^{n} w_{i} d_{i}}{\sum_{i=1}^{n} w_{i}} = \frac{\sum_{i=1}^{n} d_{i}}{n}
\end{equation}
\begin{equation} \label{eq:variance_observed_unweighted}
    \hat{\sigma}^2_{d} = \frac{\sum_{i=1}^{n} w_{i} (d_{i}-\bar{d})}{\sum_{i=1}^{n} w_{i}} = \frac{\sum_{i=1}^{n} (d_{i}-\bar{d})}{n}
\end{equation}
\hspace{0.5cm} \textit{if} $n_{pre} = \bar{n}_{pre}$ and $n_{post} = \bar{n}_{post}$