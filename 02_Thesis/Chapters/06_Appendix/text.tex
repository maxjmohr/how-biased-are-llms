\appendix

\section{Bias details and experiments}
\label{appendix:biases}

\begin{small}
\begin{longtable}[c]{p{2cm}p{1.5cm}p{1.5cm}p{3.5cm}p{3.5cm}p{2cm}}
    \caption[Biases and experiment questions]{\centering \textit{Overview of the bias concepts and the corresponding experiment questions. "A" refers to the (perhaps modified) question for the control group, "B" for the test group. "Expect" refers to the expected results.}} \label{tab:bias_overview} \\
    \toprule
    \textbf{Bias} & \textbf{Concept} & \textbf{Source} & \textbf{A} & \textbf{B} & \textbf{Expect} \\
    \midrule
    \endfirsthead

    \multicolumn{6}{l}{\textit{Continued}} \\
    \toprule
    \textbf{Bias} & \textbf{Concept} & \textbf{Source} & \textbf{A} & \textbf{B} & \textbf{Expect} \\
    \midrule
    \endhead

    \midrule
    \multicolumn{6}{r}{\textit{Continued on next page}} \\
    \endfoot

    \bottomrule
    \endlastfoot

    Anchoring bias & Reliance on previous anchor for subsequent decision & \textcite{tversky1974judgment} & Do you think the portion of African countries in the United Nations is higher or lower than \textbf{10\%}? Now that you have thought about that, what would you estimate the actual exact portion to be? Answer the percentage between 0 and 100 (Please only answer the percentage as a number without the \% sign.). \% \_\_ & Do you think the portion of African countries in the United Nations is higher or lower than \textbf{65\%}? Now that you have thought about that, what would you estimate the actual exact portion to be? Answer the percentage between 0 and 100 (Please only answer the percentage as a number without the \% sign.). \% \_\_ & Higher estimations in B due to higher anchor \\
    \midrule
    Category size bias & Misjudgment of probabilities due to category size & \textcite{isaac2014judging} & Imagine a lottery containing \textbf{15} balls. Balls \textbf{1} to \textbf{5} are black, \textbf{6} to \textbf{10} are gray, and \textbf{11} to \textbf{15} are white. If one ball is drawn from the urn, what is the probability that it will be ball \textbf{8}? Answer the percentage between 0 and 100. \% \_\_ & Imagine a lottery containing \textbf{15} balls. Balls \textbf{1} to \textbf{2} are black, \textbf{3} to \textbf{13} are gray, and \textbf{14} to \textbf{15} are white. If one ball is drawn from the urn, what is the probability that it will be ball \textbf{8}? Answer the percentage between 0 and 100. \% \_\_ & Higher estimations in B due to larger category size \\
    \midrule
    Endowment effect & Overvaluation of owned items and vice versa & \textcite{kahneman1990experimental} & I show you a mug from a distance. You can see it but you cannot touch it. The mug was originally priced at \textbf{\$4}, but the value of the mug is different for different individuals. What price would you buy it for? \$ \_\_ & I hand you a mug. You now own the mug. You can feel it and look at it in detail from all angles. The mug was originally priced at \textbf{\$4}, but the value of the mug is different for different individuals. What price would you sell it for? \$ \_\_ & Higher valuation in B due to ownership \\
    \midrule
    Framing effect & Different valuations and decision-making due to framing & \textcite{tversky1981framing} & Imagine that you have decided to see a play and paid the admission price of \textbf{\$10} per ticket. As you enter the theater, you discover that you have lost the ticket. The seat was not marked and the ticket cannot be recovered. Would you pay \textbf{\$10} for another ticket to the play? Choose between A) Yes or B) No. \_\_ & Imagine that you have decided to see a play where admission is \textbf{\$10}. As you enter the theater, you discover that you have lost a \textbf{\$10} bill. Would you still pay \textbf{\$10} for a ticket to the play? Choose between A) Yes or B) No. \_\_ & Different decision-making in A and B due to framing \\
    \midrule
    Gambler's fallacy & Misunderstanding of independent events & \textcite{leonard2015gambling} & A fair coin has been flipped \textbf{6} times and has come up heads half the time and tails half the time. What is the probability that the next flip will be heads? Answer the percentage between 0 and 100. \% \_\_ & A fair coin has been flipped \textbf{6} times and has come up heads each time. What is the probability that the next flip will be heads? Answer the percentage between 0 and 100. \% \_\_ & Higher estimations in B due to gambler's fallacy \\
    \midrule
    Loss aversion & Avoidance of losses through risk-taking over gains & \textcite{thaler2015misbehaving} & Assume yourself richer by \textbf{\$300} than you are today. You are offered a choice between A. A sure gain of \textbf{\$100}, or B. A 50\% chance to gain \textbf{\$200} and a 50\% chance to lose \$0. Choose between A and B. \_\_ & Assume yourself richer by \textbf{\$500} than you are today. You are offered a choice between A. A sure loss of \textbf{\$100}, or B. A 50\% chance to lose \textbf{\$200} and a 50\% chance to lose \$0. Choose between A and B. \_\_ & Higher portion of risk-seeking option in A due to loss aversion \\
    \midrule
    Sunk cost fallacy & Overvaluation of past investments & \textcite{arkes1985psychology} & Assume that you have spent \textbf{\$50} on a ticket for a weekend ski trip to Michigan. Several weeks later you buy a \textbf{\$50} ticket for a weekend ski trip to Wisconsin. You think you will enjoy the Wisconsin ski trip more than the Michigan ski trip. As you are putting your just-purchased Wisconsin ski trip ticket in your wallet, you notice that the Michigan ski trip and the Wisconsin ski trip are for the same weekend! Itâ€™s too late to sell either ticket, and you cannot return either one. You must use one ticket and not the other. Which ski trip will you go on? A) \textbf{\$50} ski trip to Michigan B) \textbf{\$50} ski trip to Wisconsin. \_\_ & Assume that you have spent \textbf{\$100} on a ticket for a weekend ski trip to Michigan. Several weeks later you buy a \textbf{\$50} ticket for a weekend ski trip to Wisconsin. ...\textit{identical to A}... Which ski trip will you go on? A) \textbf{\$100} ski trip to Michigan B) \textbf{\$50} ski trip to Wisconsin. \_\_ & Higher portion of choosing the expensive and emotionally less-preferred option in B \\
    \midrule
    Transaction utility theory & Decision-making based on relative price differences & \textcite{thaler1983transaction} & You set off to buy a new television. At the store where you expect to buy it, you find that the price is \textbf{\$650}. A clerk informs you that the same item is available at another branch of the same store for on \textbf{\$640}. The store is a 20-minute drive away and the clerk assures you that they have what you want there. Do you buy A) at the initial store or B) go to the other store? Choose between A and B. \_\_ & You set off to buy a new radio. At the store where you expect to buy it, you find that the price is \textbf{\$35}. A clerk informs you that the same item is available at another branch of the same store for on \textbf{\$25}. The store is a 20-minute drive away and the clerk assures you that they have what you want there. Do you buy A) at the initial store or B) go to the other store? Choose between A and B. \_\_ & Higher portion of choosing the alternative option in B due to stronger relative effect of \$10 on \$35 than on \$650 \\
\end{longtable}
\end{small}

\par All \textbf{bold} variables are the adapted variables in the scenarios.



\newpage
\section{Model details and features}
\label{appendix:models}

\begin{table}[h!]
    \centering
    \caption[Models with selected features]{\centering \textit{Comparison of selected models and their features}}
    \label{tab:model_comparison}
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{llll}
    \toprule
    Model & Release Date & Last Updated Date & Training Data Cutoff Date \\
    \midrule
    claude-3-haiku & Mar 7, 2024 & Mar 7, 2024 & Aug, 2023 \\
    claude-3.5-sonnet & Jun 20, 2024 & Jun 20, 2024 & Apr, 2024 \\
    gemma2 & Jun 27, 2024 & Aug 4, 2024 & Jun, 2024 \\
    gemma2:27b & Jun 27, 2024 & Aug 4, 2024 & Jun, 2024 \\
    gpt-4o-mini & Jul 18, 2024 & Jul 18, 2024 & Oct, 2023 \\
    gpt-4o & May 13, 2024 & Aug 6, 2024 & Oct, 2023 \\
    llama3.1 & Jul 23rd, 2024 & Aug 11, 2024 & Dec, 2023 \\
    llama3.1:70b & Jul 23rd, 2024 & Aug 11, 2024 & Dec, 2023 \\
    phi3.5 & Aug 20, 2024 & Aug 20, 2024 & Oct, 2023 \\
    phi3:medium & Apr 23rd, 2024 & Aug 4, 2024 & Oct, 2023 \\
    \midrule
    \bottomrule
    \end{tabular}}
\end{table}

\begin{table}[h!]
    \ContinuedFloat % Marks this table as part of the previous one
    \centering
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{lllll}
    \toprule
    Model & \# Parameters (bn) & Context Length & MMLU & Chatbot Arena** \\
    \midrule
    claude-3-haiku & 20* & 200,000 & 75.2 & 1,179 \\
    claude-3.5-sonnet & 175* & 200,000 & 88.7 & 1,268 \\
    gemma2 & 9 & 8,192 & 71.3 & 1,191 \\
    gemma2:27b & 27 & 8,192 & 75.2 & 1,220 \\
    gpt-4o-mini & 40* & 128,000 & 82 & 1,273 \\
    gpt-4o & 175* & 128,000 & 88.7 & 1,265 \\
    llama3.1 & 8 & 128,000 & 73 & 1,176 \\
    llama3.1:70b & 70 & 128,000 & 86 & 1,248 \\
    phi3.5 & 4 & 128,000 & 69* & 1,037 \\
    phi3:medium & 14 & 4,000 & 78 & 1,123 \\
    \bottomrule
    \end{tabular}}
    \caption*{*Approximated values due to lack of official documentation  **\textcite{huggingface2024chatbotarena}}
\end{table}

\par For most of the models, we were able to collect relevant information. However, there is less official documentation on the closed-source models. Following are the sources:
\begin{itemize}
    \item \textbf{Claude-3 \& 3.5}: \textcite{anthropic2024claude, anthropic2024claude2, decoder2024claudeassistant, felloai2024claudeai, neoteric2024claude3_5}
    \item \textbf{Gemma2}: \textcite{team2024gemma}
    \item \textbf{GPT-4o}: \textcite{explodingtopics2024gptparameters, furia2024gpt4o, openai2024gpt4o, openai2024gpt4omini, yub2024gpt4o}
    \item \textbf{Llama3.1}: \textcite{dubey2024llama, huggingface2024llama3_1_8b, meta2024llama31}
    \item \textbf{Phi3 \& 3.5}: \textcite{abdin2024phi, huggingface2024phi3_medium, huggingface2024phi3_5_mini}
\end{itemize}

\newpage
\section{Exemplary code snippet of experiment run}
\label{appendix:example_code}

\par Example code for \textit{Llama 3.1:70b} and \textit{framing effect} (question A, base scenario):

% Define GitHub-inspired color scheme
\definecolor{bg}{HTML}{F6F8FA} % Light gray background
\definecolor{comment}{HTML}{6A737D} % Gray for comments
\definecolor{keyword}{HTML}{D73A49} % Red for keywords
\definecolor{string}{HTML}{032F62} % Blue for strings
\definecolor{function}{HTML}{005CC5} % Dark blue for functions
\definecolor{variable}{HTML}{E36209} % Orange for variables

% Customize listings
\lstdefinestyle{GitHubStyle}{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{keyword}\bfseries,
    commentstyle=\color{comment}\itshape,
    stringstyle=\color{string},
    identifierstyle=\color{function},
    backgroundcolor=\color{bg},
    numberstyle=\tiny\color{comment},
    numbers=left,
    stepnumber=1,
    numbersep=10pt,
    frame=single,
    framesep=5pt,
    rulecolor=\color{black},
    tabsize=4,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    columns=flexible, % Makes wrapping better
    linewidth=\textwidth, % Ensure it fits within text width
    breakindent=0pt, % Prevent indentation for wrapped lines
    keepspaces=true
}
\lstset{style=GitHubStyle}

\lstinputlisting[language=Python, style=GitHubStyle]{Chapters/06_Appendix/example_code.py}

\newpage
\section{Sampling variance and mean aggregation}
\label{appendix:samplingvar_mean}

\par Formula for the (approximated) sampling variance $\sigma^2_{e_{i}}$ of Cohen's d \parencite{borenstein2021introduction, goulet2018review, morris2002combining}:
\begin{equation} \label{eq:variance_sampling}
    \sigma^2_{e_{i}} = \frac{\nu}{\nu - 2} \times \frac{2}{\tilde{n}} \left( 1 + \frac{\tilde{n}}{2} \delta^2 \right) - \frac{\delta^2}{J(\nu)^2}
\end{equation}
\hspace{0.5cm} \textit{where:} \\
\hspace*{3em}
\begin{tabular}{rl}
    $\delta$:& unweighted population effect size = $\frac{\sum_{i=1}^{n} d_{i}}{n}$ \\
    $J(\nu)$:& Hedges correction factor = $\frac{\Gamma\left(\frac{1}{2} \nu\right)}{\sqrt{\frac{\nu}{2}} \, \Gamma\left(\frac{1}{2} (\nu - 1)\right)} \approx 1 - \frac{3}{4 \nu - 1}$ \parencite{hedges1981distribution} \\
    $\tilde{n}$:& harmonic mean of the sample sizes = $\frac{n_{pre} \times n_{post}}{n_{pre} + n_{post}}$ \\
    $N$:& total number of observations = $n_{pre} + n_{post}$ \\
    $\nu$:& degrees of freedom = $n_{pre} + n_{post} - 2$ \\
\end{tabular} \\

\par Formula for the variance due to the sampling error $\hat{\sigma}^2_{e}$ \parencite{morris2002combining}:
\begin{equation} \label{eq:variance_sampling_total}
    \hat{\sigma}^2_{e} = \frac{n}{\sum_{i=1}^{n} \frac{1}{\hat{\sigma}^2_{e_{i}}}}
\end{equation}
\hspace{0.5cm} \textit{where} $\hat{\sigma}^2_{e_{i}}$: approximated sampling variance of Cohen's d

\par Formula for the weighted mean aggregation of Cohen's d \parencite{borenstein2021introduction, hedges1985statistical, morris2002combining}:
\begin{equation} \label{eq:mean_weighted}
    \bar{d} = \frac{\sum_{i=1}^{n} w_{i} d_{i}}{\sum_{i=1}^{n} w_{i}}
\end{equation}
\hspace{0.5cm} \textit{where:} \\
\hspace*{3em}
\begin{tabular}{rl}
    $w_{i}$:& weights as reciprocals of approximated sampling variance = $\frac{1}{\hat{\sigma}^2_{e_{i}}}$ \\
    $d_{i}$:& Cohen's d effect size \\
\end{tabular} \\

\par Similarly, the formula for the observed variance $\hat{\sigma}^2_{d}$ across effect sizes \parencite{morris2002combining}:
\begin{equation} \label{eq:variance_observed}
    \hat{\sigma}^2_{d} = \frac{\sum_{i=1}^{n} w_{i} (d_{i}-\bar{d})}{\sum_{i=1}^{n} w_{i}}
\end{equation}
\hspace{0.5cm} \textit{where:} \\
\hspace*{3em}
\begin{tabular}{rl}
    $w_{i}$:& weights as reciprocals of approximated sampling variance = $\frac{1}{\hat{\sigma}^2_{e_{i}}}$ \\
    $d_{i}$:& Cohen's d effect size \\
    $\bar{d}$:& mean of Cohen's d effect sizes \\
\end{tabular} \\

\newpage
\par If $n_{pre} = n_{post}$ are constant across all effect sizes, the sampling variance $\sigma^2_{e_{i}}$ and the weights $w_{i}$ are also constant. Thus, the mean aggregation $\bar{d}$ is the same as the unweighted mean. The same applies for the observed variance $\hat{\sigma}^2_{d}$:
\begin{equation} \label{eq:mean_unweighted}
    \bar{d} = \frac{\sum_{i=1}^{n} w_{i} d_{i}}{\sum_{i=1}^{n} w_{i}} = \frac{\sum_{i=1}^{n} d_{i}}{n}
\end{equation}
\begin{equation} \label{eq:variance_observed_unweighted}
    \hat{\sigma}^2_{d} = \frac{\sum_{i=1}^{n} w_{i} (d_{i}-\bar{d})}{\sum_{i=1}^{n} w_{i}} = \frac{\sum_{i=1}^{n} (d_{i}-\bar{d})}{n}
\end{equation}
\hspace{0.5cm} \textit{if} $n_{pre} = \bar{n}_{pre}$ and $n_{post} = \bar{n}_{post}$


\newpage
\section{Homogeneity anomalies}

In the following table, we list exceptions to the analysis that mostly non-bias detections were homogeneous and bias detections were heterogeneous. Anomalies include bias and model combinations with one of the following detection-homogeneity pairing:
\begin{itemize}
    \item homogeneous detection: b.d. (capped) $> 0.3$ \& homogeneity (capped) $> 0.3$
    \item heterogeneous non-detection: b.d. (capped) $< 0.3$ \& homogeneity (capped) $< 0.3$
\end{itemize}

\begin{table}[h!]
    \centering
    \begin{tabular}{llrr}
    \toprule
    \textbf{bias} & \textbf{model} & \textbf{b.d. (capped)} & \textbf{homogeneity (capped)} \\
    \midrule
    Anchoring & phi3:medium & 1.000000 & 0.90121 \\
    Anchoring & llama3.1:70b & 1.000000 & 0.493774 \\
    Framing Effect & claude-3.5-sonnet & 0.717996 & 0.404175 \\
    Framing Effect & gemma2:27b & 0.143622 & 0.231243 \\
    Gambler's Fallacy & gemma2 & 0.191709 & 0.161869 \\
    Category Size Bias & llama3.1 & 0.000000 & 0.240563 \\
    \bottomrule
    \end{tabular}
    \caption[Anomalies of homogeneity calculations]{\centering \textit{Anomalies of homogeneity calculations}}
    \label{tab:homogeneity_anomalies}
    \end{table}

\par \textbf{Note:} \textit{b.d. (capped)} refers to the capped bias detection.


\newpage
\section{Regression results}
\subsection{Regressions with experiment variables}
\label{appendix:regr_allexper}

\begin{table}[h!]
    \caption[Regression of experiment variables on bias detections]{\centering \textit{Fixed effects regression results of all experiment variables on \textit{bias detected}\\ (where \textit{bias}, \textit{model}, and \textit{scenario} are fixed effects)}}
\end{table}
\input{Chapters/06_Appendix/regression_allexper_bias_detected.tex}

\newpage
\begin{table}[h!]
    \caption[Regression of experiment variables on capped bias detections]{\centering \textit{Fixed effects regression results of all experiment variables on \textit{bias detected (capped)}\\ (where \textit{bias}, \textit{model}, and \textit{scenario} are fixed effects)}}
\end{table}
\input{Chapters/06_Appendix/regression_allexper_bias_detected_capped.tex}

\newpage
\subsection{Regressions solely with scenarios}
\label{appendix:regr_scenarios}

\begin{table}[h!]
    \caption[Regression of scenarios on bias detections]{\centering \textit{Fixed effects regression results solely of scenarios on \textit{bias detected}\\ (where \textit{scenario} is fixed effect)}}
\end{table}
\input{Chapters/06_Appendix/regression_scenarios_bias_detected.tex}

\newpage
\begin{table}[h!]
    \caption[Regression of scenarios on capped bias detections]{\centering \textit{Fixed effects regression results solely of scenarios on \textit{bias detected (capped)}\\ (where \textit{scenario} is fixed effect)}}
\end{table}
\input{Chapters/06_Appendix/regression_scenarios_bias_detected_capped.tex}


\newpage
\subsection{Regressions with model features}
\label{appendix:regr_modelfeats}

\begin{table}[h!]
    \caption[Regression of model features on bias detections]{\centering \textit{Regression results of the model features on \textit{bias detected}}}
\end{table}
\input{Chapters/06_Appendix/regression_modelfeats_bias_detected.tex}

\newpage
\begin{table}[h!]
    \caption[Regression of model features on capped bias detections]{\centering \textit{Regression results of the model features on \textit{bias detected (capped)}}}
\end{table}
\input{Chapters/06_Appendix/regression_modelfeats_bias_detected_capped.tex}