\section{Existing literature}
\label{chapter:theoreticalbackground}

\subsection{Previous research on human behavioral effects}
\par The study of human behavior has been a central focus of research in psychology, economics, and neuroscience as it provides insights into how individuals make decisions and interact with their environment \parencite{juarez2018analyzing}. In trying to explain behavioral patterns, researchers have identified various cognitive biases that influence human decision-making. Generally, cognitive biases refer to systematic patterns of deviation from rational judgment or objective standards \parencite{tversky1974judgment}. While traditional decision-making theories, such as classical economics, assume that individuals make decisions based on logic and reason, research over the past several decades has demonstrated that human decision-making is deeply influenced by psychological factors, leading to predictable errors in judgment. In fact, \textcite{juarez2018analyzing} estimates that 70\% of all decisions by humans are affected by cognitive biases. \textcite{kahneman2017thinking} argues that these biases are the result of an attempt to simplify complex information, but often at the expense of accuracy and rationality.

\par One influential theory to challenge the notion of human rationality is \textit{Bounded Rationality}, introduced by Herbert \textcite{simon1990bounded}. Simon proposed that humans generally strive to make rational decisions. However, they can be limited for various reasons such as limited available information, cognitive limitations or time pressure. Instead of optimizing the decision, humans often weigh the costs and benefits of the decision and select the first option that meets a certain threshold of acceptability. This behavior is also known as \textit{Satisficing} \parencite{simon1990bounded}. Another significant contribution to the understanding of cognitive biases is the \textit{Prospect Theory} developed by \textcite{kahneman1979prospect}. This theory challenges the traditional economic view of human decision-making by stating that individuals do not always act in ways that maximize expected utility, i.e. they are not always rational. Instead, humans tend to overweight potential losses compared to equivalent gains, a phenomenon known as \textit{Loss Aversion}. They also evaluate outcomes relative to a reference point (often the status quo) rather than considering absolute values. The implications of \textit{Prospect Theory} are profound, as it suggests that human behavior systematically deviates from the predictions of classical economic models, especially under conditions of risk and uncertainty.

\par Over time, research has led to the identification of more than 180 biases, often through the lens of neuroscience and behavioral economics \parencite{azzopardi2021cognitive}. As the field has advanced, researchers have developed frameworks to categorize when cognitive biases occur. \textcite{arnott1998taxonomy}, for example, proposed a taxonomy of cognitive biases based on different abstraction levels and situations. \textcite{dimara2018task} present a taxonomy for cognitive biases (for information visualization) based on the tasks they are associated with, such as decisions, estimations or hypothesis assessment. \textcite{kahneman2017thinking} researched the underlying reasons for the occurrence of these biases and introduced the concept that humans operate and decide using two distinct modes of thinking: an automatic, fast, and intuitive system (\textit{System 1}) and a conscious, slow, and analytical system (\textit{System 2}). He argues that \textit{System 1} is responsible for most of the cognitive biases, as it operates automatically and effortlessly, while \textit{System 2} is responsible for more deliberate and controlled thinking.

\par Cognitive biases are not necessarily harmful. \textcite{gigerenzer2007gut} argues that cognitive biases can be beneficial in certain situations, as they allow individuals to make quick decisions in complex environments. For example, the \textit{Availability Heuristic} allows individuals to make decisions based on readily available information, which can be useful in situations where quick decisions are required. Recently, researchers have also started to investigate and develop interventions that help individuals recognize and counteract biases, such as nudges \parencite{thaler2008nudge}.


\subsection{Leveraging large language models to simulate human behavior}
\par The development of natural language processing (NLP) is rapid and ongoing. Progressing from statistical models with simple next token predictions based on the Markov Theorem (previous token as the best predictor) over neural language modelling with recurrent neural networks (RNNs) to LLMs, the field has seen significant advancements in the past decade \parencite{zhao2023survey}. LLMs are a class of neural networks that are trained on large corpora of text data to predict the next token in a sequence of text. They differentiate themselves from other models by their architectures and by their size (number of parameters) which allows them to capture more complex, non-linear patterns in the data. These models have achieved state-of-the-art performance on a various NLP tasks, such as text classification, question answering, and language translation \parencite{naveed2023comprehensive, zhao2023survey}.

\par The success of LLMs has led to their widespread adoption in various areas. However, experts have pointed out that the uneducated usage of such models could lead to unwanted and potentially unnoticed behavior. While training a LLM, there are different ways in which biases can be incorporated. Firstly, the data used to train the model may contain biases \parencite{bender2021dangers, naveed2023comprehensive, zhao2023survey}. Training data often includes text, code or other forms of human-generated data, from sources like books, articles or websites as well as user-generated content like social media posts or comments. These data sources can contain desired as well as undesired biases. \textcite{gebru2021datasheets} emphasize the presence of biases and suggest accompanying each training dataset with a "datasheet" that documents the data collection and recommended uses. It is thus important to preprocess and clean the data before training a LLM. Transparency of LLM providers e.g., such as "datasheets" can help to understand the data sources and the preprocessing steps taken \parencite{naveed2023comprehensive, zhao2023survey}.

\par Secondly, developers desire that their models possess human values and ethical standards, known as human alignment. Often, developers optimize their models for specific tasks and correct output formatting for human-like responses, i.e. instruction tuning \parencite{zhao2023survey}. The collection of human feedback is also a common approach to ensure this alignment. This technique is known as Reinforcement Learning with Human Feedback (RLHF). While in some approaches humans compare entire model responses and rate them, i.e. \textit{outcome-supervised} RLHF, other approaches convey more granularity rating intermediate steps, e.g. sentence or word reasoning, i.e. \textit{process-supervised} RLHF \parencite{zhao2023survey}. Other methods leverage the same idea for the data collection from the beginning and thus ensure human alignment in the training process \parencite{ouyang2022training}. The various methods emphasize in how many ways biases can be introduced into LLMs.

\par The possible inclusion of biases in language models has also led to growing research contributions to the field of cognitive biases and human behavior in LLMs. \textcite{talboy2023challenging} qualitatively assess LLM responses and indicate the existence of several cognitive biases in a small selection of language models. From their assessments, they also present best practices in the usage of LLMs. \textcite{dominguez2023questioning} focus on investigating biases occurring in human surveys (e.g. ordering and labeling bias) and compare the response distributions of humans and LLMs, thus using a quantitative approach. They further demonstrate that through prompt adjustments e.g., randomized ordering of options, the model responses tend towards uniform random distributions (no ordering bias). \textcite{echterhoff2024cognitive} are close to our research goals as they observe the presence of cognitive biases in LLMs and present a framework to debiasing the models. However, they use customized quantitative metrics for each bias and do not emphasize on a standardized metric across all experiments. While they can quantitatively assess the biases, they cannot directly compare the biases' presence and magnitudes.

\par There also exists research promoting the idea to consciously include cognitive biases into AI algorithms to enhance the efficiency of the models decision-making and faster learning from less data \parencite{hagendorff2024we, taniguchi2018machine}. As previously stated, biased decision-making in LLMs can both be seen as beneficial and harmful, depending on the context, e.g. assisting in law enforcement or healthcare vs. human resources or market researches \parencite{haltaufderheide2024ethics, zhao2023survey}. The interest in applying LLMs in market research is growing as research shows that for certain scenarios, the models already decide realistically and comparably to humans. Using LLMs in market research can be beneficial as they enable faster and more cost-effective data collection \parencite{brand2023using}. For scenarios where the responses still lack human-like intuition, studies suggest that the models can be further aligned with different prompt structuring, fine-tuning and new model generations \parencite{brand2023using, qiu2023much}.